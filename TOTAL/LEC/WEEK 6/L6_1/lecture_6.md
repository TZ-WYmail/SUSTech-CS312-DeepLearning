# æ·±åº¦å­¦ä¹ å…¥é—¨ï¼šä¼˜åŒ–ä¸æ­£åˆ™åŒ–ï¼ˆä¸‹ï¼‰

> ä½œè€…ï¼šå—æ–¹çš„ç‹®å­å…ˆç”Ÿ
> æ—¥æœŸï¼š2025-10
> å…³é”®è¯ï¼šæƒé‡åˆå§‹åŒ–ã€æ•°æ®é¢„å¤„ç†ã€æ‰¹å½’ä¸€åŒ–ã€æ¢¯åº¦æ¶ˆå¤±ã€æ·±åº¦å­¦ä¹ åŸºç¡€

---

## 1. ä¸ºå•¥åˆè®²ä¼˜åŒ–ï¼Ÿâ€”â€”å› ä¸ºâ€œèµ·ç‚¹â€å†³å®šæˆè´¥

ä¸Šå›æˆ‘ä»¬èŠåˆ°**æ¢¯åº¦ä¸‹é™ã€åŠ¨é‡ã€å­¦ä¹ ç‡ã€L2 æ­£åˆ™**ã€‚  
è¿™å›æŠŠå‰©ä¸‹ 4 ä¸ªâ€œè®­ç»ƒå¿…è¸©å‘â€ä¸€æ¬¡è®²é€ï¼š

| æ¨¡å— | ä¸€å¥è¯ä½œç”¨ |
|---|---|
| æƒé‡åˆå§‹åŒ– | åˆ«è®©ç½‘ç»œâ€œå¤©ç”Ÿâ€å°±å¯¹ç§°æˆ–çˆ†ç‚¸ |
| è¾“å…¥å½’ä¸€åŒ– | æŠŠæ•°æ®â€œæ‹‰é½â€å†å–‚ç½‘ç»œ |
| æ‰¹å½’ä¸€åŒ–ï¼ˆBNï¼‰ | è®©æ¯å±‚è¾“å…¥åˆ†å¸ƒç¨³å¦‚è€ç‹— |
| æ¿€æ´»å‡½æ•°é€‰æ‹© | åˆ«è®©æ¢¯åº¦â€œä¸­é€”çŒæ­»â€ |

---

## 2. æƒé‡åˆå§‹åŒ–â€”â€”ç»™ç½‘ç»œä¸€ä¸ªâ€œä¸å¯¹ç§°â€çš„ç«¥å¹´ï¼ˆassignment 1 å†™ä¹‹å‰åˆæ²¡è®²ï¼Œæå¾—æ•ˆæœæ¯”è¾ƒå·®ï¼‰

### 2.1 ä¸‰å¤§å¿Œè®³
1. å…¨é›¶åˆå§‹åŒ– â†’ æ‰€æœ‰ç¥ç»å…ƒ**å¯¹ç§°æ›´æ–°**ï¼Œå­¦ä¸åˆ°ä¸œè¥¿  ï¼ˆweight asymmetricityï¼‰
2. è¿‡å¤§åˆå§‹åŒ–ï¼ˆLarge weightsï¼‰ â†’ **æ¢¯åº¦çˆ†ç‚¸**ã€æ¿€æ´»é¥±å’Œï¼ˆsigmoid/tanhï¼‰  
3. è¿‡å°åˆå§‹åŒ– â†’ **ä¿¡å·æ¶ˆå¤±**ï¼Œåå‘ä¼ ä¸åŠ¨

### 2.2 æ­£ç¡®å§¿åŠ¿ï¼ˆå¦‚ä½•ç»™ä¸åŒçš„æ¿€æ´»å‡½æ•°é€‰æ‹©æ­£ç¡®çš„åˆå§‹åŒ–æ–¹æ³•ï¼‰
| æ¿€æ´»å‡½æ•° | æ¨èåˆå§‹åŒ–å…¬å¼ | ä»£ç ç‰‡æ®µï¼ˆPyTorchï¼‰ |
|---|---|---|
| tanh / softmax | Xavier æ­£æ€ï¼š$$ \mathcal{N}(0,\frac{2}{n_{in}+n_{out}}) $$ | `nn.init.xavier_normal_(m.weight)` |
| ReLU åŠå…¶å˜ç§ | Kaiming æ­£æ€ï¼š$$ \mathcal{N}(0,\frac{2}{n_{in}}) $$ | `nn.init.kaiming_normal_(m.weight, nonlinearity='relu')` |

> è®°å¿†å£è¯€ï¼š**â€œtanh ç”¨ Xavierï¼ŒReLU ç”¨ Kaimingâ€**

### å¤ä¹ ï¼š
Tanhï¼ˆåŒæ›²æ­£åˆ‡ï¼‰æ¿€æ´»å‡½æ•°çš„å…¬å¼å¦‚ä¸‹ï¼š

![alt text](image-4.png)


---

### ç‰¹ç‚¹æ€»ç»“ï¼š

| ç‰¹æ€§        | æè¿°                                                                 |
|-------------|----------------------------------------------------------------------|
| è¾“å‡ºèŒƒå›´     | (-1, 1)ï¼Œ**é›¶ä¸­å¿ƒåŒ–**ï¼ˆzero-centeredï¼‰                              |
| å¯¼æ•°         | \(1 - \tanh^2(x)\)ï¼Œåœ¨ 0 é™„è¿‘æ¢¯åº¦æœ€å¤§ï¼Œä¸¤ç«¯é¥±å’ŒåŒºæ¢¯åº¦æ¥è¿‘ 0               |
| ä¼˜ç‚¹         | ç›¸æ¯” Sigmoidï¼Œè¾“å‡ºå‡å€¼ä¸º 0ï¼Œæ”¶æ•›æ›´å¿«                                  |
| ç¼ºç‚¹         | ä¸¤ç«¯ä»å¯èƒ½**æ¢¯åº¦æ¶ˆå¤±**ï¼ˆé¥±å’ŒåŒºï¼‰                                      |
| å¸¸è§ç”¨é€”     | RNNã€LSTMã€GRU ä¸­çš„é—¨æ§ä¿¡å·ï¼›å°å‹å…¨è¿æ¥ç½‘ç»œ                             |

---

### Python ä»£ç ç¤ºä¾‹ï¼ˆNumPyï¼‰ï¼š

```python
import numpy as np

def tanh(x):
    return np.tanh(x)  # NumPy å·²å†…ç½®

# ç¤ºä¾‹
x = np.array([-2, -1, 0, 1, 2])
print(tanh(x))  # è¾“å‡º: [-0.96402758 -0.76159416  0.          0.76159416  0.96402758]
```


å¯¹æ¯”è¯¾ä»¶ä¸Šçš„å†…å®¹
### tanhï¼š![alt text](image-1.png)![alt text](image.png)
- å‡åŒ€åˆ†å¸ƒ ï¼ˆ6/ï¼ˆm+nï¼‰ï¼‰
- æ­£æ€åˆ†å¸ƒ ï¼ˆ1/mï¼‰


### ReLUåˆå§‹åŒ–ï¼š![alt text](image-2.png)
- å‡åŒ€åˆ†å¸ƒ 4ï¼ˆ6/ï¼ˆm+nï¼‰ï¼‰
- æ­£æ€åˆ†å¸ƒ ï¼ˆ2/mï¼‰
---

## 3. æ•°æ®é¢„å¤„ç†â€”â€”æŠŠåƒç´ æ‹‰å›â€œäººé—´â€

### 3.1 é›¶å‡å€¼ + å•ä½æ–¹å·®ï¼ˆStandardizationï¼‰
```python
from torchvision import transforms
transform = transforms.Compose([
    transforms.ToTensor(),                      # 0~1
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])  # ImageNet ç»Ÿè®¡å€¼
]) 
```

å¥½å¤„ï¼š
- è®©**æ¿€æ´»å€¼**è½åœ¨æ¢¯åº¦æœ€å¤§åŒºåŸŸï¼ˆå¦‚ tanh çš„çº¿æ€§åŒºï¼‰
- ä¸åŒç‰¹å¾**æ¢¯åº¦é‡çº§ä¸€è‡´**ï¼Œæ”¶æ•›æ›´å¿«

### 3.2 åæ–¹å·®å½’ä¸€åŒ–ï¼ˆç™½åŒ–ï¼Œè¿›é˜¶ï¼‰
- æŠŠç‰¹å¾ç»´åº¦**å»ç›¸å…³**ï¼Œè®©æ¤­åœ†ç­‰é«˜çº¿å˜åœ†ï¼Œæ¢¯åº¦æ–¹å‘æ›´ä¼˜
- è®¡ç®—é‡å¤§ï¼Œé€šå¸¸åªåœ¨å°æ•°æ®é›†/ç¬¬ä¸€å±‚ä½¿ç”¨

---

## 4. æ‰¹å½’ä¸€åŒ–ï¼ˆBatchNormï¼‰â€”â€”è®­ç»ƒåŠ é€Ÿå¤–æŒ‚ï¼ˆåŠ¨æ‰‹æ·±åº¦å­¦ä¹ ä¸­æåˆ°å…¶ä¼¼ä¹å¢å¤§äº†æ•°æ®çš„å™ªéŸ³ï¼‰

### é‡è¦æ¡ä»¶ï¼š  Two important principles.
-  zero-centredä»¥é›¶ä¸ºä¸­å¿ƒ
-  constant through time and data (mini-batches)æ—¶é—´å’Œæ•°æ®ä¸å˜ï¼ˆå°æ‰¹é‡ï¼‰
### 4.1 åŠ¨æœº
> â€œInternal Covariate Shiftâ€ï¼šå‰é¢å±‚ä¸€æ›´æ–°ï¼Œåé¢å±‚è¾“å…¥åˆ†å¸ƒå°±â€œæ¼‚ç§»â€ï¼Œè¢«è¿«ä¸åœé‡æ–°é€‚åº”ã€‚

### 4.2 åšæ³•ï¼ˆä¸€å¥è¯ï¼‰
å¯¹æ¯ä¸ª**mini-batch**çš„æ¯ä¸ªé€šé“åšï¼š
1. ç®—å‡å€¼ & æ–¹å·®
2. é›¶å‡å€¼å•ä½æ–¹å·®
3. å†**ç¼©æ”¾+å¹³ç§»**ï¼ˆå¯å­¦å‚æ•° Î³, Î²ï¼‰

å…¬å¼ï¼šï¼ˆå°†æ¯ä¸€ä¸ªç‚¹å¤„ç†ä¸€ä¸‹ï¼‰ï¼ˆè®°å¿†å…¬å¼ï¼‰
$$
\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}, \quad y_i = \gamma \hat{x}_i + \beta
$$
![alt text](image-3.png)
### 4.3 æ•ˆæœ
- å­¦ä¹ ç‡å¯ä»¥**æ”¾å¤§ 5Ã—** ä¸ç‚¸
- å¯¹åˆå§‹æƒé‡**ä¸å†æ•æ„Ÿ**
- è½»å¾®**æ­£åˆ™åŒ–**æ•ˆæœï¼ˆè®­ç»ƒæ—¶ç»Ÿè®¡é‡æœ‰å™ªå£°ï¼‰

### 4.4 ä½¿ç”¨å°è´´å£«
- æ”¾åœ¨**å·ç§¯/çº¿æ€§å±‚ä¹‹å**ï¼Œ**æ¿€æ´»å‡½æ•°ä¹‹å‰**ï¼ˆä¸»æµåšæ³•ï¼‰
- è®­ç»ƒæ—¶ `model.train()`ï¼Œæ¨ç†æ—¶ `model.eval()` ä¼šè‡ªåŠ¨åˆ‡æ¢ç»Ÿè®¡é‡
- batch_size è¿‡å°æ—¶ï¼ˆ<8ï¼‰å»ºè®®æ”¹ç”¨ **GroupNorm / LayerNorm**

---

## 5. æ¿€æ´»å‡½æ•°å†å›é¡¾â€”â€”â€œæ­»äº¡ ReLUâ€æ€ä¹ˆç ´ï¼Ÿ

| å‡½æ•° | å½¢çŠ¶ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨ |
|---|---|---|---|---|
| Sigmoid | ä¸¤å¤´é¥±å’Œ | æ¦‚ç‡è§£é‡Š | æ¢¯åº¦æ¶ˆå¤± | è¾“å‡ºå±‚äºŒåˆ†ç±» |
| Tanh | é›¶ä¸­å¿ƒ | æ¯” sigmoid å¼º | ä»æœ‰é¥±å’Œ | å°ç½‘ç»œ |
| ReLU | å•ä¾§çº¿æ€§ | å¿«ã€ç®€å• | ç¥ç»å…ƒâ€œæ­»äº¡â€ | å¤§å¤šæ•° CNN |
| LeakyReLU | è´Ÿå¡å°æ–œç‡ | ç¼“è§£æ­»äº¡ | å¤šè¶…å‚ | è‡ªå®šä¹‰ |
| ELU/Swish | å¹³æ»‘è´ŸåŒº | ç²¾åº¦+ | è®¡ç®—+ | ç«èµ›åˆ·åˆ† |

> é»˜è®¤é¡ºåºï¼š**ReLU â†’ LeakyReLU â†’ Swish**ï¼ˆå…ˆè¯•æœ€ç®€å•çš„ï¼‰

---

## 6. ä¸€æ¡é¾™è®­ç»ƒæ¨¡æ¿ï¼ˆPyTorch ç‰ˆï¼‰

```python
class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(784, 256),
            nn.BatchNorm1d(256),   # BN åœ¨æ¿€æ´»å‰
            nn.ReLU(inplace=True),
            nn.Linear(256, 10)
        )
        # æƒé‡åˆå§‹åŒ–
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')

    def forward(self, x):
        return self.fc(x)

# ä¼˜åŒ–å™¨ + å­¦ä¹ ç‡è°ƒåº¦
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)
```

---

## 7. å¸¸è§è¸©å‘ FAQ

| ç°è±¡ | å¯èƒ½åŸå›  | å¿«é€Ÿæ’æŸ¥ |
|---|---|---|
| è®­ç»ƒ loss ä¸é™ | å­¦ä¹ ç‡å¤ªå° / æ•°æ®æ²¡å½’ä¸€åŒ– | å…ˆæ‰“å°ç¬¬ä¸€å±‚æ¿€æ´»å‡å€¼æ–¹å·® |
| éªŒè¯ç²¾åº¦éœ‡è¡å¤§ | BN ç»Ÿè®¡é‡ä¸å‡† | æŠŠ batch_size è°ƒåˆ° â‰¥16 |
| ReLU å…¨é›¶è¾“å‡º | åˆå§‹æƒé‡å…¨è´Ÿ / å­¦ä¹ ç‡è¿‡é«˜ | ç”¨ LeakyReLU æˆ–é™å­¦ä¹ ç‡ |
| æ¢¯åº¦çˆ†ç‚¸ | æƒé‡åˆå§‹åŒ–å¤ªå¤§ | åŠ  gradient clipping + Kaiming |

---

## 8. æ€»ç»“è„‘å›¾

```text
æ·±åº¦å­¦ä¹ è®­ç»ƒæµç¨‹
â”œâ”€â”€ æ•°æ®
â”‚   â””â”€â”€ å½’ä¸€åŒ–ï¼ˆé›¶å‡å€¼ / ç™½åŒ–ï¼‰
â”œâ”€â”€ æ¨¡å‹
â”‚   â”œâ”€â”€ æƒé‡åˆå§‹åŒ–ï¼ˆXavier / Kaimingï¼‰
â”‚   â”œâ”€â”€ æ¿€æ´»å‡½æ•°ï¼ˆReLU å®¶æ—ï¼‰
â”‚   â””â”€â”€ æ‰¹å½’ä¸€åŒ–ï¼ˆBN / GNï¼‰
â”œâ”€â”€ ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ å­¦ä¹ ç‡ + è°ƒåº¦å™¨
â”‚   â””â”€â”€ æ­£åˆ™åŒ–ï¼ˆL2 + BN éšå¼ï¼‰
â””â”€â”€ è°ƒå‚
    â””â”€â”€ ç›‘æ§æ¢¯åº¦ / æ¿€æ´»åˆ†å¸ƒ
```

---

## 9. ä¸‹ä¸€æ­¥å­¦ä»€ä¹ˆï¼Ÿ
- æ›´æ·±çš„ç½‘ç»œ â†’ **æ®‹å·®ç»“æ„ï¼ˆResNetï¼‰**
- æ›´ç¨³çš„ BN â†’ **LayerNorm / Weight Standardization**
- æ›´çŒ›çš„ä¼˜åŒ–å™¨ â†’ **AdamW + cosine / OneCycle**

---

## 10. ä¸€é”®è¿è¡Œ Demo

GitHub ä»“åº“ï¼ˆå« notebook + æ•°æ®ï¼‰  
[https://github.com/yourname/dl-optimization-101](https://github.com/yourname/dl-optimization-101)  
clone åç›´æ¥ï¼š
```bash
pip install -r requirements.txt
jupyter notebook 01_mnist_baseline.ipynb
```

---

ğŸ‰ **å¦‚æœæœ¬æ–‡å¸®åˆ°ä½ ï¼Œè®°å¾—ç‚¹èµ + æ”¶è— + å…³æ³¨ï¼Œè¯„è®ºåŒºä¸€èµ·äº¤æµè¸©å‘å²ï¼**
```